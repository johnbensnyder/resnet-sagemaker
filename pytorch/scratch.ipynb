{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import pytorch_lightning as pl\n",
    "import webdataset as wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_classes, resnet_version,\n",
    "                 train_path, val_path, optimizer='adamw',\n",
    "                 lr=1e-3, batch_size=64,\n",
    "                 dataloader_workers=4, \n",
    "                 *args, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__dict__.update(locals())\n",
    "        \n",
    "        resnets = {\n",
    "            18:tv.models.resnet18,\n",
    "            34:tv.models.resnet34,\n",
    "            50:tv.models.resnet50,\n",
    "            101:tv.models.resnet101,\n",
    "            152:tv.models.resnet152\n",
    "        }\n",
    "        \n",
    "        optimizers = {\n",
    "            'adam': torch.optim.Adam,\n",
    "            'adamw': torch.optim.AdamW,\n",
    "            'sgd': torch.optim.SGD\n",
    "        }\n",
    "        \n",
    "        self.optimizer = optimizers[optimizer]\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.model = resnets[resnet_version]()\n",
    "        linear_size = list(self.model.children())[-1].in_features\n",
    "        self.model.fc = torch.nn.Linear(linear_size, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer(self.parameters(), lr=self.lr)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        preproc = tv.transforms.Compose([\n",
    "                tv.transforms.ToTensor(),\n",
    "                tv.transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                                        (0.229, 0.224, 0.225)),\n",
    "                tv.transforms.Resize((224, 224))\n",
    "            ])\n",
    "        dataset = wds.WebDataset(self.train_path).shuffle(1024) \\\n",
    "                        .decode(\"pil\").to_tuple(\"jpeg\", \"cls\").map_tuple(preproc, lambda x:x)\n",
    "        return torch.utils.data.DataLoader(dataset, \n",
    "                                           num_workers=self.dataloader_workers, \n",
    "                                           batch_size=self.batch_size)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        preproc = tv.transforms.Compose([\n",
    "                tv.transforms.ToTensor(),\n",
    "                tv.transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                                        (0.229, 0.224, 0.225)),\n",
    "                tv.transforms.Resize((224, 224))\n",
    "            ])\n",
    "        dataset = wds.WebDataset(self.val_path).shuffle(1024) \\\n",
    "                        .decode(\"pil\").to_tuple(\"jpeg\", \"cls\").map_tuple(preproc, lambda x:x)\n",
    "        return torch.utils.data.DataLoader(dataset, \n",
    "                                           num_workers=self.dataloader_workers, \n",
    "                                           batch_size=self.batch_size)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = self.criterion(preds, y)\n",
    "        acc = (y == torch.argmax(preds, 1)).type(torch.FloatTensor).mean()\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = self.criterion(preds, y)\n",
    "        acc = (y == torch.argmax(preds, 1)).type(torch.FloatTensor).mean()\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlSageMakerLogger(pl.Callback):\n",
    "    \n",
    "    def __init__(self, frequency=10):\n",
    "        self.frequency=frequency\n",
    "        self.step = 0\n",
    "        \n",
    "    def on_epoch_start(self, trainer, module, *args, **kwargs):\n",
    "        self.inner_step = 0\n",
    "    \n",
    "    def on_train_batch_end(self, trainer, module, *args, **kwargs):\n",
    "        if self.inner_step%self.frequency==0:\n",
    "            print(' '.join([\"{0}: {1:.4f}\".format(i, float(j)) for i,j in trainer.logged_metrics.items()]))\n",
    "        self.inner_step += 1\n",
    "        self.step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'num_classes': 1000,\n",
    "                'resnet_version': 50,\n",
    "                'train_path': 'pipe:aws s3 cp s3://jbsnyder-sagemaker-us-east/data/imagenet/train/train_{0000..2047}.tar -',\n",
    "                'val_path': 'pipe:aws s3 cp s3://jbsnyder-sagemaker-us-east/data/imagenet/val/val_{0000..0127}.tar -',\n",
    "                'optimizer': 'adamw',\n",
    "                'lr': 1e-3, \n",
    "                'batch_size': 64,\n",
    "                'dataloader_workers': 0}\n",
    "\n",
    "trainer_params = {'gpus': torch.cuda.device_count(),\n",
    "                  'num_nodes': 0,\n",
    "                  'strategy': 'ddp' if torch.cuda.device_count()>1 else None,\n",
    "                  'max_epochs': 4,\n",
    "                  'amp_backend': 'apex',\n",
    "                  'amp_level': 'O2',\n",
    "                  'precision': 16,\n",
    "                  'progress_bar_refresh_rate': 0,\n",
    "                  'callbacks': [PlSageMakerLogger()]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit apex Automatic Mixed Precision (AMP)\n",
      "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(**model_params)\n",
    "trainer = pl.Trainer(**trainer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | model     | ResNet           | 25.6 M\n",
      "-----------------------------------------------\n",
      "25.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.228   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "[2022-01-04 00:32:06.148 pytorch-1-8-gpu-py36-ml-p3-2xlarge-84493874ea1d5c2b56c14072735a:17560 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-01-04 00:32:06.177 pytorch-1-8-gpu-py36-ml-p3-2xlarge-84493874ea1d5c2b56c14072735a:17560 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "train_loss_step: 7.2882 train_acc_step: 7.2882\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "train_loss_step: 8.1000 train_acc_step: 8.1000\n",
      "train_loss_step: 7.6759 train_acc_step: 7.6759\n",
      "train_loss_step: 7.3552 train_acc_step: 7.3552\n",
      "train_loss_step: 7.2716 train_acc_step: 7.2716\n",
      "train_loss_step: 7.0613 train_acc_step: 7.0613\n",
      "train_loss_step: 7.0754 train_acc_step: 7.0754\n",
      "train_loss_step: 6.8918 train_acc_step: 6.8918\n",
      "train_loss_step: 7.0324 train_acc_step: 7.0324\n",
      "train_loss_step: 6.9047 train_acc_step: 6.9047\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = model.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Processor' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-21746c208d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# Cannot statically verify that dataset is Sized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_IterableDataset_len_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# IterableDataset doesn't allow custom sampler or batch_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Processor' has no len()"
     ]
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.8-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
